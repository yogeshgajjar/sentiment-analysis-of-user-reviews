{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from wordcloud import ImageColorGenerator\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filelist):\n",
    "    \"\"\"\n",
    "    Creates dataframe of the dataset by UCI - Sentiment Analysis \n",
    "\n",
    "    :param filelist: list of file directory.\n",
    "    \"\"\"\n",
    "    #UCI dataset Dataframe\n",
    "    df_uci = pd.concat([pd.read_csv(item, header=None, sep='\\t') for item in filelist], axis=0)\n",
    "    df_uci.columns = ['reviews', 'sentiment']\n",
    "    \n",
    "    #IMDB dataset DataFrame\n",
    "    reviews_train = []\n",
    "    for line in open('/home/yogesh/fall19/ml660/project/movie_data/full_train.txt', 'r'):\n",
    "        reviews_train.append(line.strip())\n",
    "    \n",
    "    df_imdb_train = pd.DataFrame(reviews_train, columns=['reviews'])\n",
    "    \n",
    "    reviews_test = []\n",
    "    for line in open('/home/yogesh/fall19/ml660/project/movie_data/full_test.txt', 'r'):\n",
    "        reviews_test.append(line.strip())\n",
    "    \n",
    "    df_imdb_test = pd.DataFrame(reviews_train, columns=['reviews'])\n",
    "    \n",
    "    return df_uci, df_imdb_train, df_imdb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/amazon_cells_labelled.txt', '/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/imdb_labelled.txt', '/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/yelp_labelled.txt']\n",
    "df_uci, df_imdb_train, df_imdb_test = read_file(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uci.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uci.to_csv('df_uci.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetselection(df_uci, df_imdb_train, df_imdb_test):\n",
    "    # use argv method to call configuration from the call\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if sys.argv[1] == '1':\n",
    "        print(\"This includes training on 80% of whole dataset and testing on 20%\")\n",
    "        df_train_data = pd.concat([pd.DataFrame(df_uci['reviews']), df_imdb_train, df_imdb_test], axis=0)\n",
    "        y = pd.concat([pd.DataFrame(df_uci['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])])    \n",
    "        X = tfidfvectorization(df_train_data) \n",
    "        y = y['sentiment'].to_numpy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    if sys.argv[2] == '2':\n",
    "        print(\"This includes Train/Test on UCI dataset\")\n",
    "        df_train_data = pd.DataFrame(df_uci['reviews'])\n",
    "        y = pd.DataFrame(df_uci['sentiment'])\n",
    "        X = tfidfvectorization(df_train_data) \n",
    "        y = y['sentiment'].to_numpy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        \n",
    "    if sys.argv[3] == '3':\n",
    "        print(\"This includes train on IMDB and test on UCI dataset\")\n",
    "        df_train_data, df_test_data = pd.concat([df_imdb_train, df_imdb_test]), pd.DataFrame(df_uci['reviews'], axis=0)\n",
    "        y_train, y_test = pd.concat([pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])]), df_uci['sentiment']\n",
    "        X_train, X_test = tfidfvectorization(df_train_data), tfidfvectorization(df_test_data)\n",
    "#         X_train, X_test = shuffle(X.iloc[:50000], random_state=7), shuffle(X.iloc[50000:], random_state=7)\n",
    "#         y_train, y_test = shuffle(y.iloc[:50000], random_state=7), shuffle(y.iloc[50000:], random_state=7)\n",
    "        \n",
    "#         y = y['sentiment'].to_numpy()\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        \n",
    "    return df_train_data, y\n",
    "\n",
    "# df_train_data, y = datasetselection(df_uci, df_imdb_train, df_imdb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This includes Train/Test on UCI dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"This includes Train/Test on UCI dataset\")\n",
    "df_train_data = pd.DataFrame(df_uci['reviews'])\n",
    "y = pd.DataFrame(df_uci['sentiment'])\n",
    "X = tfidfvectorization(df_train_data) \n",
    "y = y['sentiment'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This includes train on IMDB and test on UCI dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"This includes train on IMDB and test on UCI dataset\")\n",
    "df_train_data, df_test_data = pd.concat([df_imdb_train, df_imdb_test]), pd.DataFrame(df_uci['reviews'])\n",
    "y_train, y_test = pd.concat([pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])]), df_uci['sentiment']\n",
    "X_train, X_test = tfidfvectorization(df_train_data), tfidfvectorization(df_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2748x4498 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17493 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfvectorization(df):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    df_array = df['reviews'].to_numpy()\n",
    "    word_list = []\n",
    "    for i in range(len(df_array)):\n",
    "        tokens_new = word_tokenize(df_array[i])\n",
    "        words = [word for word in tokens_new if word.isalpha()]\n",
    "        words = [stemmer.lemmatize(word) for word in words]\n",
    "        doc = ' '.join(words)\n",
    "        word_list.append(doc) \n",
    "    \n",
    "#     return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "\n",
    "#     tfidfconv = TfidfVectorizer(lowercase=True, stop_words=stopwords.words('english'), max_features=2000, min_df=2, max_df=0.7)\n",
    "    tfidfconv = TfidfVectorizer(max_features=4000, stop_words=stopwords.words('english'))\n",
    "    X = tfidfconv.fit_transform(word_list)\n",
    "#     print(X.toarray().shape) \n",
    "    return X\n",
    "\n",
    "# X = tfidfvectorization(df_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(X, y):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    y = y['sentiment'].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#     print(X_train.shape)\n",
    "#     print(type(X_test))\n",
    "#     print(y_train.shape)\n",
    "#     print(y_test.shape) \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestB(X,y):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    parameters = {'C': np.logspace(-2,3,6)}\n",
    "    mod_lr = LogisticRegression()\n",
    "    \n",
    "    clf = GridSearchCV(mod_lr, parameters, cv=5)  # gridsearchCV with 5 fold CV\n",
    "    clf.fit(X_train, y_train)\n",
    "    lambda_scale = 1/clf.best_params_.get('C')  # calculating the best lambda \n",
    "    \n",
    "    \n",
    "    score_scale = clf.best_score_   # Average cross validation score to calculate the error \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    train_score = 1 - accuracy_score(y_train, y_pred_train)  # Calculating train error \n",
    "    test_score = 1 - accuracy_score(y_test, y_pred_test) # Calculating test error \n",
    "    print(\"-----Logistic Regression--------\") \n",
    "    print(confusion_matrix(y_test,y_pred_test))\n",
    "    print(classification_report(y_test,y_pred_test))\n",
    "    print(accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "#     sel_ = SelectFromModel(LogisticRegression(C= (1/clf.best_params_.get('C')), penalty='l1'))\n",
    "#     sel_.fit(X_train_fit, y_train)\n",
    "#     print(\"For l:\", i)\n",
    "#     selected_feat = X_train.columns[(sel_.get_support())]\n",
    "#     print('selected features: {}'.format(len(selected_feat)))\n",
    "#     print('c value', clf.best_params_.get('C'))\n",
    "#     print('The best score:', clf.best_score_)\n",
    "#     plist.append(len(selected_feat))\n",
    "#     score.append(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "    classifier.fit(X_train, y_train) \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "#     print(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearSVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    parameters = {'C': np.logspace(-2,3,6)}\n",
    "    # GridsearchCV used to identify the best parameters from the range declared above. \n",
    "    gs = GridSearchCV(LinearSVC(), parameters, cv = 5)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    #Instanciating of the classifier LinearSVC to train SVC with kernel Linear and l1-penalized with loss = squared hinge loss. \n",
    "    svc = LinearSVC(penalty='l2', loss='squared_hinge', dual = False, C = gs.best_params_.get('C'))\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "#     loss_f_l1 = hamming_loss(y_test.loc[:,'Family'], y_pred_f_l1)\n",
    "\n",
    "    print(\"CLASSIFICATION USING L1 PENALIZED SVM WITH LINEAR KERNEL\")\n",
    "#     print(\"LABEL - FAMILY\")\n",
    "#     print(\"\")\n",
    "    print(\"Test Score is :\", svc.score(X_test, y_test, sample_weight=None))\n",
    "#     print(\"Hamming loss is :\", loss_f_l1)\n",
    "    print(\"Best Penalty is:\", gs.best_params_.get('C'))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbfSVM(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    parameters = {'C': np.logspace(-2,3,6), 'gamma': np.linspace(0.05,2)}\n",
    "    #parameters = {'C': np.linspace(0.1, 100, 100), 'gamma': np.linspace(0.05,0.1,2)}\n",
    "\n",
    "    # GridsearchCV used to identify the best parameters from the range declared above. \n",
    "    gs = GridSearchCV(SVC(kernel='rbf'), parameters, cv = 10)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    #Instanciating of the classifier OneVsRest to train SVC with kernel RBF. \n",
    "    estimator = SVC(C = gs.best_params_.get('C'), kernel = 'rbf', gamma = gs.best_params_.get('gamma'))\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)     # Calculates the y_pred value. \n",
    "#     loss_g = hamming_loss(y_test, y_pred)     #The indiviadual hamming loss is calculated. \n",
    "\n",
    "    print(\"CLASSIFICATION USING SVM WITH RBF KERNEL\")\n",
    "#     print(\"LABEL - GENUS\")\n",
    "#     print(\"\")\n",
    "    print(\"Test Score is :\", estimator.score(X_test, y_test, sample_weight=None))\n",
    "#     print(\"Hamming loss is :\", loss_g)\n",
    "    print(\"Best Penalty is:\", gs.best_params_.get('C'), \"and Best Gamma is :\", gs.best_params_.get('gamma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Logistic Regression--------\n",
      "[[5143  184]\n",
      " [ 180 5043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      5327\n",
      "           1       0.96      0.97      0.97      5223\n",
      "\n",
      "    accuracy                           0.97     10550\n",
      "   macro avg       0.97      0.97      0.97     10550\n",
      "weighted avg       0.97      0.97      0.97     10550\n",
      "\n",
      "0.9654976303317535\n"
     ]
    }
   ],
   "source": [
    "filelist = ['/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/amazon_cells_labelled.txt', '/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/imdb_labelled.txt', '/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/yelp_labelled.txt']\n",
    "df_uci, df_imdb_train, df_imdb_test = read_file(filelist)\n",
    "\n",
    "df_train_data, y = datasetselection(df_uci, df_imdb_train, df_imdb_test)\n",
    "X = tfidfvectorization(df_train_data)\n",
    "X_train, X_test, y_train, y_test = test_train_split(X, y)\n",
    "# randomforest(X_train, X_test, y_train, y_test) \n",
    "logisticRegression(X_train, X_test, y_train, y_test)\n",
    "# linearSVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION USING L1 PENALIZED SVM WITH LINEAR KERNEL\n",
      "Test Score is : 0.9611374407582939\n",
      "Best Penalty is: 10.0\n",
      "0.9611374407582939\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = test_train_split(X, y)\n",
    "# randomforest(X_train, X_test, y_train, y_test) \n",
    "# logisticRegression(X_train, X_test, y_train, y_test)\n",
    "linearSVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION USING L1 PENALIZED SVM WITH LINEAR KERNEL\n",
      "Test Score is : 0.9611374407582939\n",
      "Best Penalty is: 10.0\n",
      "0.9611374407582939\n"
     ]
    }
   ],
   "source": [
    "linearSVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfSVM(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This includes train on IMDB and test on UCI dataset\n",
      "(50000, 4000)\n",
      "(2748, 4000)\n",
      "(2748,)\n",
      "(50000, 1)\n",
      "-----Logistic Regression--------\n",
      "[[694 668]\n",
      " [722 664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50      1362\n",
      "           1       0.50      0.48      0.49      1386\n",
      "\n",
      "    accuracy                           0.49      2748\n",
      "   macro avg       0.49      0.49      0.49      2748\n",
      "weighted avg       0.49      0.49      0.49      2748\n",
      "\n",
      "0.49417758369723436\n"
     ]
    }
   ],
   "source": [
    "print(\"This includes train on IMDB and test on UCI dataset\")\n",
    "df_train_data, df_test_data = pd.concat([df_imdb_train, df_imdb_test]), pd.DataFrame(df_uci['reviews'])\n",
    "y_train, y_test = pd.concat([pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])]), df_uci['sentiment']\n",
    "X_train, X_test = tfidfvectorization(df_train_data), tfidfvectorization(df_test_data)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "parameters = {'C': np.logspace(-2,3,6)}\n",
    "mod_lr = LogisticRegression()\n",
    "\n",
    "clf = GridSearchCV(mod_lr, parameters, cv=5)  # gridsearchCV with 5 fold CV\n",
    "clf.fit(X_train, y_train)\n",
    "lambda_scale = 1/clf.best_params_.get('C')  # calculating the best lambda \n",
    "\n",
    "\n",
    "score_scale = clf.best_score_   # Average cross validation score to calculate the error \n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "train_score = 1 - accuracy_score(y_train, y_pred_train)  # Calculating train error \n",
    "test_score = 1 - accuracy_score(y_test, y_pred_test) # Calculating test error \n",
    "print(\"-----Logistic Regression--------\") \n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCI_train_data = []\n",
    "UCI_train_labels = []\n",
    "\n",
    "with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/amazon_cells_labelled.txt\", 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "\n",
    "for review in content:\n",
    "    UCI_train_data.append(review.split(\"\\t\")[0])\n",
    "    UCI_train_labels.append(review.split(\"\\t\")[1])\n",
    "\n",
    "with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/imdb_labelled.txt\", 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "\n",
    "for review in content:\n",
    "    UCI_train_data.append(review.split(\"\\t\")[0])\n",
    "    UCI_train_labels.append(review.split(\"\\t\")[1])\n",
    "\n",
    "with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/yelp_labelled.txt\", 'r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "\n",
    "for review in content:\n",
    "    UCI_train_data.append(review.split(\"\\t\")[0])\n",
    "    UCI_train_labels.append(review.split(\"\\t\")[1])\n",
    "\n",
    "df_uci_train = pd.DataFrame(UCI_train_data, columns=['reviews'])\n",
    "df_uci_labels = pd.DataFrame(UCI_train_labels, columns=['sentiment'])\n",
    "df_uci = pd.concat([df_uci_train, df_uci_labels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment\n",
       "0            0\n",
       "1            1\n",
       "2            1\n",
       "3            0\n",
       "4            1\n",
       "5            0\n",
       "6            0\n",
       "7            1\n",
       "8            0\n",
       "9            0\n",
       "10           1\n",
       "11           1\n",
       "12           0\n",
       "13           1\n",
       "14           0\n",
       "15           1\n",
       "16           0\n",
       "17           1\n",
       "18           1\n",
       "19           0\n",
       "20           0\n",
       "21           1\n",
       "22           0\n",
       "23           1\n",
       "24           0\n",
       "25           1\n",
       "26           1\n",
       "27           0\n",
       "28           0\n",
       "29           0\n",
       "...        ...\n",
       "2970         0\n",
       "2971         0\n",
       "2972         0\n",
       "2973         0\n",
       "2974         0\n",
       "2975         0\n",
       "2976         0\n",
       "2977         0\n",
       "2978         0\n",
       "2979         0\n",
       "2980         0\n",
       "2981         0\n",
       "2982         0\n",
       "2983         0\n",
       "2984         0\n",
       "2985         0\n",
       "2986         0\n",
       "2987         0\n",
       "2988         0\n",
       "2989         0\n",
       "2990         0\n",
       "2991         0\n",
       "2992         0\n",
       "2993         0\n",
       "2994         0\n",
       "2995         0\n",
       "2996         0\n",
       "2997         0\n",
       "2998         0\n",
       "2999         0\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uci_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from wordcloud import ImageColorGenerator\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uci_data():\n",
    "    UCI_train_data = []\n",
    "    UCI_train_labels = []\n",
    "\n",
    "    with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/amazon_cells_labelled.txt\", 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "\n",
    "    for review in content:\n",
    "        UCI_train_data.append(review.split(\"\\t\")[0])\n",
    "        UCI_train_labels.append(review.split(\"\\t\")[1])\n",
    "\n",
    "    with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/imdb_labelled.txt\", 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "\n",
    "    for review in content:\n",
    "        UCI_train_data.append(review.split(\"\\t\")[0])\n",
    "        UCI_train_labels.append(review.split(\"\\t\")[1])\n",
    "\n",
    "    with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/yelp_labelled.txt\", 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "\n",
    "    for review in content:\n",
    "        UCI_train_data.append(review.split(\"\\t\")[0])\n",
    "        UCI_train_labels.append(review.split(\"\\t\")[1])\n",
    "        \n",
    "    df_uci_train = pd.DataFrame(UCI_train_data, columns=['reviews'])\n",
    "    df_uci_labels = pd.DataFrame(UCI_train_labels, columns=['sentiment'])\n",
    "    df_uci = pd.concat([df_uci_train, df_uci_labels], axis = 1)\n",
    "    return df_uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filelist):\n",
    "    \"\"\"\n",
    "    Creates dataframe of the dataset by UCI - Sentiment Analysis \n",
    "\n",
    "    :param filelist: list of file directory.\n",
    "    \"\"\"\n",
    "    #UCI dataset Dataframe\n",
    "#     df_uci = pd.concat([pd.read_csv(item, header=None, sep='\\t') for item in filelist], axis=0)\n",
    "#     df_uci.columns = ['reviews', 'sentiment']\n",
    "    df_uci = uci_data()\n",
    "    #IMDB dataset DataFrame\n",
    "    reviews_train = []\n",
    "    for line in open('/home/yogesh/fall19/ml660/project/movie_data/full_train.txt', 'r'):\n",
    "        reviews_train.append(line.strip())\n",
    "    \n",
    "    df_imdb_train = pd.DataFrame(reviews_train, columns=['reviews'])\n",
    "    \n",
    "    reviews_test = []\n",
    "    for line in open('/home/yogesh/fall19/ml660/project/movie_data/full_test.txt', 'r'):\n",
    "        reviews_test.append(line.strip())\n",
    "    \n",
    "    df_imdb_test = pd.DataFrame(reviews_train, columns=['reviews'])\n",
    "    \n",
    "    return df_uci, df_imdb_train, df_imdb_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_uci, df_imdb_train, df_imdb_test = read_file(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = shuffle(pd.concat([pd.DataFrame(df_uci.iloc[0:2401,0]), df_imdb_train, df_imdb_test], axis=0), random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52401, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train(df_uci, df_imdb_test, df_imdb_train, target):\n",
    "    if (target == 1): #2199\n",
    "        df_train_data = shuffle(pd.concat([pd.DataFrame(df_uci.iloc[0:2401,0]), df_imdb_train, df_imdb_test], axis=0), random_state = 7)\n",
    "        df_test_data = shuffle(pd.DataFrame(df_uci.iloc[2401:,0]), random_state=7)\n",
    "        y_train = shuffle(pd.concat([pd.DataFrame(df_uci.iloc[0:2401, 1]), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])]), random_state = 7)   \n",
    "        y_test = shuffle(pd.DataFrame(df_uci.iloc[2401:, 1]), random_state = 7)\n",
    "\n",
    "    if (target == 2):\n",
    "        df_train_data = pd.concat([pd.DataFrame(df_uci['reviews']), df_imdb_train, df_imdb_test.iloc[0:20000]], axis=0)\n",
    "        df_test_data = df_imdb_test.iloc[20000:]\n",
    "        y_train = pd.concat([pd.DataFrame(df_uci['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(20000)], columns=['sentiment'])])    \n",
    "        y_test = pd.DataFrame([1 for i in range(5000)], columns=['sentiment'])\n",
    "    \n",
    "    return df_train_data, df_test_data, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetselection(df_uci, df_imdb_train, df_imdb_test):\n",
    "    # use argv method to call configuration from the call\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "#     if sys.argv[1] == '1':\n",
    "#     print(\"This includes training on 80% of whole dataset and testing on 20%\")\n",
    "#     df_train_data = pd.concat([pd.DataFrame(df_uci['reviews']), df_imdb_train, df_imdb_test], axis=0)\n",
    "#     y = pd.concat([pd.DataFrame(df_uci['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])])    \n",
    "#     X = tfidfvectorization(df_train_data) \n",
    "# #     y = y['sentiment'].to_numpy()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    \n",
    "#     elif sys.argv[1] == '2':\n",
    "#     print(\"This includes Train/Test on UCI dataset\")\n",
    "#     df_train_data = pd.DataFrame(df_uci['reviews'])\n",
    "#     y = pd.DataFrame(df_uci['sentiment'])\n",
    "#     X = tfidfvectorization(df_train_data) \n",
    "#     y = y['sentiment'].to_numpy()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#     elif sys.argv[1] == '3':\n",
    "    print(\"This includes train on IMDB and test on UCI dataset\")\n",
    "    df_train_data, df_test_data = shuffle(pd.concat([df_imdb_train, df_imdb_test]), random_state = 7), shuffle(pd.DataFrame(df_uci['reviews']), random_state = 7)\n",
    "    y_train, y_test = shuffle(pd.concat([pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])]), random_state = 7), shuffle(pd.DataFrame(df_uci['sentiment'], columns=['sentiment']), random_state = 7)\n",
    "    X_train, X_test = tfidfvectorization(df_train_data), tfidfvectorization(df_test_data)\n",
    "\n",
    "#     elif sys.argv[1] == '4':\n",
    "#         print(\"This includes Train/Test on IMDB dataset\")\n",
    "#         y_train, y_test = shuffle(pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), random_state = 7), shuffle(pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), random_state = 7)\n",
    "#         df_imdb_train, df_imdb_test = shuffle(df_imdb_train, random_state = 7), shuffle(df_imdb_test, random_state = 7)\n",
    "#         X_train, X_test = tfidfvectorization(df_imdb_train), tfidfvectorization(df_imdb_test)\n",
    "        \n",
    "#     elif sys.argv[1] == '5':\n",
    "#     print(\"This includes Training on 100% IMDB + 80% UCI and Test on 20% UCI\")\n",
    "#     df_train_data, df_test_data, y_train, y_test = split_train(df_uci, df_imdb_test, df_imdb_train, 1)\n",
    "#     X_train, X_test = tfidfvectorization(df_train_data), tfidfvectorization(df_test_data)\n",
    "\n",
    "\n",
    "#     elif sys.argv[1] == '6':\n",
    "#     print(\"This includes Training on 100% UCI + 80% IMDB and Test on 20% IMDB\")\n",
    "# #     print(\"This includes Training on 100% IMDB + 80% UCI and Test on 20% UCI\")\n",
    "#     df_train_data, df_test_data, y_train, y_test = split_train(df_uci, df_imdb_test, df_imdb_train, 2)\n",
    "#     X_train, X_test = tfidfvectorization(df_train_data), tfidfvectorization(df_test_data)\n",
    "\n",
    "#     else:\n",
    "#         print(\"done\")\n",
    "    # print(\"This includes training on 80% of whole dataset and testing on 20%\")\n",
    "    # df_train_data = pd.concat([pd.DataFrame(df_uci['reviews']), df_imdb_train, df_imdb_test], axis=0)\n",
    "    # y = pd.concat([pd.DataFrame(df_uci['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])])    \n",
    "    \n",
    "    # if sys.argv[2] == '2':\n",
    "    #     print(\"This includes training on 100% UCI dataset + 80% of Imdb dataset and testing on 20% Imdb dataset\")\n",
    "    #     df_train_data = pd.concat([pd.DataFrame(df_uci['reviews']), ])\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print(y_train.shape) \n",
    "#     return X_train, X_test, y_train, y_test, y\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This includes train on IMDB and test on UCI dataset\n",
      "(50000, 66409)\n",
      "(3000, 4498)\n",
      "(3000, 1)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "filelist = ['/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/amazon_cells_labelled.txt', '/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/imdb_labelled.txt', '/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/yelp_labelled.txt']\n",
    "df_uci, df_imdb_train, df_imdb_test = read_file(filelist)\n",
    "\n",
    "X_train, X_test, y_train, y_test = datasetselection(df_uci, df_imdb_train, df_imdb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306    1\n",
       "2037    0\n",
       "568     1\n",
       "1897    1\n",
       "2498    1\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(\"y_train.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['sentiment'] = y_train.sentiment.astype(float)\n",
    "y_test['sentiment'] = y_test.sentiment.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 31366 features per sample; expecting 66741",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-599f2c6face0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscore_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m   \u001b[0;31m# Average cross validation score to calculate the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Calculating train error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculating test error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \"\"\"\n\u001b[1;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 270\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 31366 features per sample; expecting 66741"
     ]
    }
   ],
   "source": [
    "parameters = {'C': np.logspace(-2,3,6)}\n",
    "mod_lr = LogisticRegression()\n",
    "\n",
    "clf = GridSearchCV(mod_lr, parameters, cv=5)  # gridsearchCV with 5 fold CV\n",
    "clf.fit(X_train, y_train)\n",
    "lambda_scale = 1/clf.best_params_.get('C')  # calculating the best lambda \n",
    "\n",
    "\n",
    "score_scale = clf.best_score_   # Average cross validation score to calculate the error \n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "train_score = 1 - accuracy_score(y_train, y_pred_train)  # Calculating train error \n",
    "test_score = 1 - accuracy_score(y_test, y_pred_test) # Calculating test error \n",
    "print(\"-----Logistic Regression--------\") \n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfvectorization(df):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    df_array = df['reviews'].to_numpy()\n",
    "    word_list = []\n",
    "    for i in range(len(df_array)):\n",
    "        tokens_new = word_tokenize(df_array[i])\n",
    "        words = [word for word in tokens_new if word.isalpha()]\n",
    "        words = [stemmer.lemmatize(word) for word in words]\n",
    "        doc = ' '.join(words)\n",
    "        word_list.append(doc) \n",
    "    \n",
    "#     return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "\n",
    "#     tfidfconv = TfidfVectorizer(lowercase=True, stop_words=stopwords.words('english'), max_features=2000, min_df=2, max_df=0.7)\n",
    "    # if sys.argv[1] == '3':\n",
    "    #     tfidfconv = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=4000, min_df=2, max_df=0.7)\n",
    "    #     X = tfidfconv.fit_transform(word_list)\n",
    "\n",
    "    tfidfconv = TfidfVectorizer(lowercase=True, stop_words=stopwords.words('english'))\n",
    "    X = tfidfconv.fit_transform(word_list)\n",
    "\n",
    "#     print(X.toarray().shape) \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(X, y):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    y = y['sentiment'].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#     print(X_train.shape)\n",
    "#     print(type(X_test))\n",
    "#     print(y_train.shape)\n",
    "#     print(y_test.shape) \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
