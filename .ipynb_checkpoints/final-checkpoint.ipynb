{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from wordcloud import ImageColorGenerator\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uciData():\n",
    "\n",
    "    \"\"\"\n",
    "    Reads UCI dataset .txt files (Amazon, IMDB, YELP), \n",
    "    Reference for uci_data collection from https://github.com/hoomanm/Sentiment-Analysis\n",
    "    :returns : DataFrame consisting of reviews and sentiments of user reviews in UCI dataset\n",
    "    \"\"\"\n",
    "\n",
    "    uci_train_data = []\n",
    "    uci_train_labels = []\n",
    "\n",
    "    with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/amazon_cells_labelled.txt\", 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "\n",
    "    for review in content:\n",
    "        uci_train_data.append(review.split(\"\\t\")[0])\n",
    "        uci_train_labels.append(review.split(\"\\t\")[1])\n",
    "\n",
    "    with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/imdb_labelled.txt\", 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "\n",
    "    for review in content:\n",
    "        uci_train_data.append(review.split(\"\\t\")[0])\n",
    "        uci_train_labels.append(review.split(\"\\t\")[1])\n",
    "\n",
    "    with open(\"/home/yogesh/fall19/ml660/project/sentiment_labelled_sentences/yelp_labelled.txt\", 'r') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "\n",
    "    for review in content:\n",
    "        uci_train_data.append(review.split(\"\\t\")[0])\n",
    "        uci_train_labels.append(review.split(\"\\t\")[1])\n",
    "        \n",
    "    df_uci_train = pd.DataFrame(uci_train_data, columns=['reviews'])\n",
    "    df_uci_labels = pd.DataFrame(uci_train_labels, columns=['sentiment'])\n",
    "    df_uci = pd.concat([df_uci_train, df_uci_labels], axis = 1)\n",
    "    return df_uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdbData():\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Reads IMDB dataset .txt files,  \n",
    "    Modified dataset downloaded from https://github.com/aaronkub/machine-learning-examples/blob/master/imdb-sentiment-analysis/movie_data.tar.gz\n",
    "    :returns df_imdb_train: DataFrame consisting train samples of user reviews in IMDB dataset\n",
    "    :returns df_imdb_test: Dataframe consisting test samples of user reviews in IMDB dataset\n",
    "    \"\"\"\n",
    "\n",
    "    reviews_train = []\n",
    "    for line in open('/home/yogesh/fall19/ml660/project/movie_data/full_train.txt', 'r'):\n",
    "        reviews_train.append(line.strip())\n",
    "    df_imdb_train = pd.DataFrame(reviews_train, columns=['reviews'])\n",
    "    \n",
    "    reviews_test = []\n",
    "    for line in open('/home/yogesh/fall19/ml660/project/movie_data/full_test.txt', 'r'):\n",
    "        reviews_test.append(line.strip())\n",
    "    df_imdb_test = pd.DataFrame(reviews_train, columns=['reviews'])\n",
    "    \n",
    "    return df_imdb_train, df_imdb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uci, df_imdb_train, df_imdb_test = uciData(), imdbData()[0], imdbData()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetSelection(df_uci, df_imdb_train, df_imdb_test, target):\n",
    "   \n",
    "    \"\"\"\n",
    "    Different configuration for train/test of the dataset based on the user defined number. \n",
    "    Total of 6 different configuration which includes - \n",
    "        1. TRAIN AND TEST ON OVERALL DATASET INCLUDING IMDB AND UCI DATASET\n",
    "        2. TRAIN AND TEST ON UCI DATASET\n",
    "        3. TRAIN ON IMDB DATASET AND TEST ON UCI DATASET\n",
    "        4. TRAIN AND TEST ON IMDB DATASET\n",
    "        5. TRAIN ON 100% IMDB + 80% UCI DATASET AND TEST ON 20% UCI DATASET\n",
    "        6. TRAIN ON 100% UCI + 80% IMDB DATASET AND TEST ON 20% IMDB DATASET\n",
    "    :param df_uci = Dataframe of UCI dataset with columns \"review\"(user review) and \"sentiment\"(label either positive or negative). \n",
    "    :param df_imdb_train = Dataframe of IMDB train dataset with only column \"review\"(user review). \n",
    "    :param df_imdb_test = Dataframe of IMDB test dataset with only column \"review\"(user review). \n",
    "    :returns X_train: Dataframe containing train samples with features extracted from TfidfVectorizer for a particular configurations specified in terminal.  \n",
    "    :returns X_test: Dataframe containing test samples with features extracted from TfidfVectorizer for a particular configurations specified in terminal. \n",
    "    :returns y_train: Dataframe containing train labels for a particular configurations specified in terminal. \n",
    "    :returns y_test: Dataframe containing test labels for a particular configurations specified in terminal. \n",
    "    \"\"\"\n",
    "\n",
    "    if target == 1:\n",
    "        print(\"TRAIN AND TEST ON OVERALL DATASET INCLUDING IMDB AND UCI DATASET\")\n",
    "        df_train_data = pd.concat([pd.DataFrame(df_uci['reviews']), df_imdb_train, df_imdb_test], axis=0)\n",
    "        y = pd.concat([pd.DataFrame(df_uci['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])])    \n",
    "        X = tfidfVectorization(df_train_data, 1) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        y_train['sentiment'], y_test['sentiment'] = y_train.sentiment.astype(float), y_test.sentiment.astype(float)\n",
    "         \n",
    "    elif target == 2:\n",
    "        print(\"TRAIN AND TEST ON UCI DATASET\")\n",
    "        df_train_data = pd.DataFrame(df_uci['reviews'])\n",
    "        y = pd.DataFrame(df_uci['sentiment'])\n",
    "        X = tfidfVectorization(df_train_data, 1) \n",
    "        # y = y['sentiment'].to_numpy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    elif target == 3:\n",
    "        print(\"TRAIN ON IMDB DATASET AND TEST ON UCI DATASET\")\n",
    "        df_train_data, df_test_data = shuffle(pd.concat([df_imdb_train, df_imdb_test]), random_state = 7), shuffle(pd.DataFrame(df_uci['reviews']), random_state = 7)\n",
    "        y_train, y_test = shuffle(pd.concat([pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])]), random_state = 7), shuffle(pd.DataFrame(df_uci['sentiment'], columns=['sentiment']), random_state = 7)\n",
    "        y_train['sentiment'], y_test['sentiment'] = y_train.sentiment.astype(float), y_test.sentiment.astype(float)\n",
    "        X_train, X_test = tfidfVectorization(df_train_data, 2), tfidfVectorization(df_test_data, 2)\n",
    "\n",
    "    elif target == 4:\n",
    "        print(\"TRAIN AND TEST ON IMDB DATASET\")\n",
    "        y_train, y_test = shuffle(pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), random_state = 7), shuffle(pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), random_state = 7)\n",
    "        df_imdb_train, df_imdb_test = shuffle(df_imdb_train, random_state = 7), shuffle(df_imdb_test, random_state = 7)\n",
    "        X_train, X_test = tfidfVectorization(df_imdb_train, 1), tfidfVectorization(df_imdb_test, 1)\n",
    "        \n",
    "    elif target == 5:\n",
    "        print(\"TRAIN ON 100% IMDB + 80% UCI DATASET AND TEST ON 20% UCI DATASET\")\n",
    "        df_train_data, df_test_data, y_train, y_test = splitTrain(df_uci, df_imdb_test, df_imdb_train, 1)\n",
    "        y_train['sentiment'] = y_train.sentiment.astype(float)\n",
    "        y_test['sentiment'] = y_test.sentiment.astype(float)\n",
    "        X_train, X_test = tfidfVectorization(df_train_data, 3), tfidfVectorization(df_test_data, 3)\n",
    "\n",
    "\n",
    "    elif target == 6:\n",
    "        print(\"TRAIN ON 100% UCI + 80% IMDB DATASET AND TEST ON 20% IMDB DATASET\")\n",
    "        df_train_data, df_test_data, y_train, y_test = splitTrain(df_uci, df_imdb_test, df_imdb_train, 2)\n",
    "        y_train['sentiment'] = y_train.sentiment.astype(float)\n",
    "        y_test['sentiment'] = y_test.sentiment.astype(float)\n",
    "        X_train, X_test = tfidfVectorization(df_train_data, 4), tfidfVectorization(df_test_data, 4)\n",
    "\n",
    "    else:\n",
    "        print(\"done\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print(y_train.shape) \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrain(df_uci, df_imdb_test, df_imdb_train, target):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Splitting the dataset for configuration 5 and 6 into their required respective configurations. \n",
    "    :param df_uci: Dataframe of UCI dataset with columns \"review\"(user review) and \"sentiment\"(label either positive or negative).\n",
    "    :param df_imdb_test: Dataframe of IMDB test dataset with only column \"review\"(user review).\n",
    "    :param df_imdb_train: Dataframe of IMDB train dataset with only column \"review\"(user review).\n",
    "    :param target: Target is an interger value which is either 1 or 2 \n",
    "    :returns df_train_data: Dataframe containing train samples with features extracted from TfidfVectorizer for a particular configurations specified in terminal. \n",
    "    :returns df_test_data: Dataframe containing test samples with features extracted from TfidfVectorizer for a particular configurations specified in terminal. \n",
    "    :returns y_train: Dataframe containing train labels for a particular configurations specified in terminal. \n",
    "    :returns y_test: Dataframe containing test labels for a particular configurations specified in terminal. \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if (target == 1): \n",
    "        df_train_data = shuffle(pd.concat([pd.DataFrame(df_uci.iloc[0:2401,0]), df_imdb_train, df_imdb_test], axis=0), random_state = 7)\n",
    "        df_test_data = shuffle(pd.DataFrame(df_uci.iloc[2401:,0]), random_state=7)\n",
    "        y_train = shuffle(pd.concat([pd.DataFrame(df_uci.iloc[0:2401, 1]), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment'])]), random_state = 7)   \n",
    "        y_test = shuffle(pd.DataFrame(df_uci.iloc[2401:, 1]), random_state = 7)\n",
    "\n",
    "    if (target == 2):\n",
    "        df_train_data = pd.concat([pd.DataFrame(df_uci['reviews']), df_imdb_train, df_imdb_test.iloc[0:20000]], axis=0)\n",
    "        df_test_data = df_imdb_test.iloc[20000:]\n",
    "        y_train = pd.concat([pd.DataFrame(df_uci['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(25000)], columns=['sentiment']), pd.DataFrame([1 if i < 12500 else 0 for i in range(20000)], columns=['sentiment'])])    \n",
    "        y_test = pd.DataFrame([1 for i in range(5000)], columns=['sentiment'])\n",
    "    \n",
    "    return df_train_data, df_test_data, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
